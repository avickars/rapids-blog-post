{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "373f39a0",
   "metadata": {},
   "source": [
    "# Creating Data Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b358d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893db9c",
   "metadata": {},
   "source": [
    "## Reading in Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6563c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the Carbon Dioxide Dataset\n",
    "co_df = cudf.read_csv(\"1980-2008-CO.csv\")\n",
    "co_df[\"RAW_VALUE\"] = co_df.RAW_VALUE.astype(float)\n",
    "co_df[\"ROUNDED_VALUE\"] = co_df.RAW_VALUE.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ffa0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the CO station information\n",
    "station_co_df = cudf.read_csv(\"bc_air_monitoring_stations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25df0cb1",
   "metadata": {},
   "source": [
    "## Creating Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e35ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(co_subset):\n",
    "    # Computing the average raw value\n",
    "    return co_subset['RAW_VALUE'].mean()\n",
    "\n",
    "def sort(co_subset):\n",
    "    # Sorting based on the raw CO value \n",
    "    return co_subset.sort_values(['RAW_VALUE'], ascending=True)\n",
    "\n",
    "def merge(co_subset, station_co_df):\n",
    "    # Merging with the CO Stations to find which station made each measurement\n",
    "    return co_subset.merge(station_co_df, how='left', on='STATION_NAME')\n",
    "\n",
    "def filters(co_subset):\n",
    "    # Filtering to the \"Victoria Topaz\" station\n",
    "    filterd_pan_df = co_subset[co_subset['STATION_NAME'] == 'Victoria Topaz']\n",
    "    \n",
    "def all_tests(co_subset, station_co_df):\n",
    "    # Computing the average raw value\n",
    "    pan_mean = co_subset['RAW_VALUE'].mean()\n",
    "\n",
    "    # Sorting based on the raw CO value \n",
    "    pan_sort_df = co_subset.sort_values(['RAW_VALUE'], ascending=True)\n",
    "\n",
    "    # Merging with the CO Stations to find which station made each measurement\n",
    "    panmerge_df = co_subset.merge(station_co_df, how='left', on='STATION_NAME')\n",
    "\n",
    "    # Filtering to the \"Victoria Topaz\" station\n",
    "    filterd_pan_df = co_subset[co_subset['STATION_NAME'] == 'Victoria Topaz']\n",
    "    \n",
    "def tester(test, co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST):    \n",
    "    if test == 'mean':\n",
    "        # Starting timer\n",
    "        t0 = time.time()   \n",
    "\n",
    "        for i in range(0,NUM_EXECUTIONS_PER_TEST):\n",
    "            mean(co_subset)\n",
    "            \n",
    "        # Stopping clock\n",
    "        t1 = time.time()\n",
    "\n",
    "        # Recording Results\n",
    "        total_time = t1-t0\n",
    "        avg_time = total_time/NUM_EXECUTIONS_PER_TEST\n",
    "\n",
    "        return total_time, avg_time\n",
    "    \n",
    "    elif test == 'sort':\n",
    "        # Starting timer\n",
    "        t0 = time.time()   \n",
    "\n",
    "        for i in range(0,NUM_EXECUTIONS_PER_TEST):\n",
    "            sort(co_subset)\n",
    "            \n",
    "        # Stopping clock\n",
    "        t1 = time.time()\n",
    "\n",
    "        # Recording Results\n",
    "        total_time = t1-t0\n",
    "        avg_time = total_time/NUM_EXECUTIONS_PER_TEST\n",
    "\n",
    "        return total_time, avg_time\n",
    "      \n",
    "    elif test == 'merge':\n",
    "        # Starting timer\n",
    "        t0 = time.time()   \n",
    "\n",
    "        for i in range(0,NUM_EXECUTIONS_PER_TEST):\n",
    "            merge(co_subset, station_co_df)\n",
    "            \n",
    "        # Stopping clock\n",
    "        t1 = time.time()\n",
    "\n",
    "        # Recording Results\n",
    "        total_time = t1-t0\n",
    "        avg_time = total_time/NUM_EXECUTIONS_PER_TEST\n",
    "\n",
    "        return total_time, avg_time\n",
    "    elif test == 'filter':\n",
    "        # Starting timer\n",
    "        t0 = time.time()   \n",
    "\n",
    "        for i in range(0,NUM_EXECUTIONS_PER_TEST):\n",
    "            filters(co_subset)\n",
    "            \n",
    "        # Stopping clock\n",
    "        t1 = time.time()\n",
    "\n",
    "        # Recording Results\n",
    "        total_time = t1-t0\n",
    "        avg_time = total_time/NUM_EXECUTIONS_PER_TEST\n",
    "\n",
    "        return total_time, avg_time\n",
    "    else:\n",
    "        # Starting timer\n",
    "        t0 = time.time()   \n",
    "\n",
    "        for i in range(0,NUM_EXECUTIONS_PER_TEST):\n",
    "            all_tests(co_subset, station_co_df)\n",
    "            \n",
    "        # Stopping clock\n",
    "        t1 = time.time()\n",
    "\n",
    "        # Recording Results\n",
    "        total_time = t1-t0\n",
    "        avg_time = total_time/NUM_EXECUTIONS_PER_TEST\n",
    "\n",
    "        return total_time, avg_time\n",
    "        \n",
    "          \n",
    "    # Stopping clock\n",
    "    t1 = time.time()\n",
    "    \n",
    "    # Recording Results\n",
    "    total_time = t1-t0\n",
    "    avg_time = total_time/NUM_EXECUTIONS_PER_TEST\n",
    "    \n",
    "    return total_time, avg_time\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f0db4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_START_ROWS = 2500\n",
    "\n",
    "NUM_EXECUTIONS_PER_TEST = 3\n",
    "\n",
    "NUM_DSIZE_DOUBLINGS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92911255",
   "metadata": {},
   "source": [
    "## Executing Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a79158",
   "metadata": {},
   "source": [
    "### RAPIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fceaa348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0\n",
      "Test: 1\n",
      "Test: 2\n",
      "Test: 3\n",
      "Test: 4\n",
      "Test: 5\n",
      "Test: 6\n",
      "Test: 7\n",
      "Test: 8\n",
      "Test: 9\n",
      "Test: 10\n"
     ]
    }
   ],
   "source": [
    "numRows = NUM_START_ROWS\n",
    "\n",
    "rapids = []\n",
    "for i in range(0, NUM_DSIZE_DOUBLINGS):\n",
    "    print('Test:', i)\n",
    "    \n",
    "    numRows = numRows * 2\n",
    "    \n",
    "    if numRows > len(co_df):\n",
    "        co_subset = co_subset.append(co_subset)\n",
    "    else:\n",
    "        co_subset = co_df.iloc[0:numRows]\n",
    "        \n",
    "    # ******************************************************************************\n",
    "    # MEAN TEST\n",
    "    \n",
    "    test = {'Test':'Mean'}\n",
    "    total_time, avg_time = tester('mean', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    rapids.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # SORT TEST\n",
    "    \n",
    "    test = {'Test':'Sort'}\n",
    "    \n",
    "    total_time, avg_time = tester('sort', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    rapids.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # MERGE TEST\n",
    "    \n",
    "    test = {'Test':'Merge'}\n",
    "    \n",
    "    total_time, avg_time = tester('merge', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    rapids.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # FILTER TEST\n",
    "    \n",
    "    test = {'Test':'Filter'}\n",
    "    \n",
    "    total_time, avg_time = tester('filter', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "        \n",
    "    rapids.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # ALL TEST\n",
    "    \n",
    "    test = {'Test':'All'}\n",
    "    \n",
    "    total_time, avg_time = tester('all', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    rapids.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "results_df_rapids = pd.DataFrame(rapids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d9ea58",
   "metadata": {},
   "source": [
    "### PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30e4e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving all DFs to CPU for pandas\n",
    "co_df = co_df.to_pandas()\n",
    "station_co_df = station_co_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fee1c228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0\n",
      "Test: 1\n",
      "Test: 2\n",
      "Test: 3\n",
      "Test: 4\n",
      "Test: 5\n",
      "Test: 6\n",
      "Test: 7\n",
      "Test: 8\n",
      "Test: 9\n",
      "Test: 10\n"
     ]
    }
   ],
   "source": [
    "numRows = NUM_START_ROWS\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(0, NUM_DSIZE_DOUBLINGS):\n",
    "    print('Test:', i)\n",
    "    numRows = numRows * 2\n",
    "    \n",
    "    if numRows > len(co_df):\n",
    "        co_subset = co_subset.append(co_subset)\n",
    "    else:\n",
    "        co_subset = co_df.iloc[0:numRows]\n",
    "        \n",
    "    dfSize_GB = sys.getsizeof(co_subset) * 10**(-9)\n",
    "        \n",
    "    # ******************************************************************************\n",
    "    # MEAN TEST\n",
    "    \n",
    "    test = {'Test Size':dfSize_GB, 'Test':'Mean'}\n",
    "    total_time, avg_time = tester('mean', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    results.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # SORT TEST\n",
    "    \n",
    "    test = {'Test Size':dfSize_GB, 'Test':'Sort'}\n",
    "    \n",
    "    total_time, avg_time = tester('sort', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    results.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # MERGE TEST\n",
    "    \n",
    "    test = {'Test Size':dfSize_GB, 'Test':'Merge'}\n",
    "    \n",
    "    total_time, avg_time = tester('merge', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    results.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # FILTER TEST\n",
    "    \n",
    "    test = {'Test Size':dfSize_GB, 'Test':'Filter'}\n",
    "    \n",
    "    total_time, avg_time = tester('filter', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "        \n",
    "    results.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # ALL TEST\n",
    "    \n",
    "    test = {'Test Size':dfSize_GB, 'Test':'All'}\n",
    "    \n",
    "    total_time, avg_time = tester('all', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    results.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "results_df_pandas = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf264b3e",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc0e412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Pandas</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Rapids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Test Size</th>\n",
       "      <th>Test</th>\n",
       "      <th>Total</th>\n",
       "      <th>Average</th>\n",
       "      <th>Test</th>\n",
       "      <th>Total</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00379</td>\n",
       "      <td>Mean</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>Mean</td>\n",
       "      <td>0.004482</td>\n",
       "      <td>0.001494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00379</td>\n",
       "      <td>Sort</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>Sort</td>\n",
       "      <td>0.028676</td>\n",
       "      <td>0.009559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00379</td>\n",
       "      <td>Merge</td>\n",
       "      <td>0.025727</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>Merge</td>\n",
       "      <td>0.048513</td>\n",
       "      <td>0.016171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00379</td>\n",
       "      <td>Filter</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>Filter</td>\n",
       "      <td>0.016682</td>\n",
       "      <td>0.005561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00379</td>\n",
       "      <td>All</td>\n",
       "      <td>0.029296</td>\n",
       "      <td>0.009765</td>\n",
       "      <td>All</td>\n",
       "      <td>0.104480</td>\n",
       "      <td>0.034827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pandas                              Rapids                    \n",
       "  Test Size    Test     Total   Average    Test     Total   Average\n",
       "0   0.00379    Mean  0.000274  0.000091    Mean  0.004482  0.001494\n",
       "1   0.00379    Sort  0.002186  0.000729    Sort  0.028676  0.009559\n",
       "2   0.00379   Merge  0.025727  0.008576   Merge  0.048513  0.016171\n",
       "3   0.00379  Filter  0.002162  0.000721  Filter  0.016682  0.005561\n",
       "4   0.00379     All  0.029296  0.009765     All  0.104480  0.034827"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.concat( \n",
    "    [\n",
    "        pd.concat({\"Pandas\": results_df_pandas}, axis=1), \n",
    "        pd.concat({\"Rapids\": results_df_rapids}, axis=1)\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "results_df.to_csv('pandas_v_rapids_results.csv')\n",
    "results_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
