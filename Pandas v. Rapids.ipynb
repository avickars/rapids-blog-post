{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "373f39a0",
   "metadata": {},
   "source": [
    "# Creating Data Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b358d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893db9c",
   "metadata": {},
   "source": [
    "## Reading in Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6563c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the Carbon Dioxide Dataset\n",
    "co_df = cudf.read_csv(\"1980-2008-CO.csv\")\n",
    "co_df[\"RAW_VALUE\"] = co_df.RAW_VALUE.astype(float)\n",
    "co_df[\"ROUNDED_VALUE\"] = co_df.RAW_VALUE.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ffa0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the CO station information\n",
    "station_co_df = cudf.read_csv(\"bc_air_monitoring_stations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25df0cb1",
   "metadata": {},
   "source": [
    "## Creating Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e35ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(co_subset):\n",
    "    # Computing the average raw value\n",
    "    return co_subset['RAW_VALUE'].mean()\n",
    "\n",
    "def sort(co_subset):\n",
    "    # Sorting based on the raw CO value \n",
    "    return co_subset.sort_values(['RAW_VALUE'], ascending=True)\n",
    "\n",
    "def merge(co_subset, station_co_df):\n",
    "    # Merging with the CO Stations to find which station made each measurement\n",
    "    return co_subset.merge(station_co_df, how='left', on='STATION_NAME')\n",
    "\n",
    "def filters(co_subset):\n",
    "    # Filtering to the \"Victoria Topaz\" station\n",
    "    filterd_pan_df = co_subset[co_subset['STATION_NAME'] == 'Victoria Topaz']\n",
    "    \n",
    "def all_tests(co_subset, station_co_df):\n",
    "    # Computing the average raw value\n",
    "    pan_mean = co_subset['RAW_VALUE'].mean()\n",
    "\n",
    "    # Sorting based on the raw CO value \n",
    "    pan_sort_df = co_subset.sort_values(['RAW_VALUE'], ascending=True)\n",
    "\n",
    "    # Merging with the CO Stations to find which station made each measurement\n",
    "    panmerge_df = co_subset.merge(station_co_df, how='left', on='STATION_NAME')\n",
    "\n",
    "    # Filtering to the \"Victoria Topaz\" station\n",
    "    filterd_pan_df = co_subset[co_subset['STATION_NAME'] == 'Victoria Topaz']\n",
    "    \n",
    "def tester(test, co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST):    \n",
    "    if test == 'mean':\n",
    "        # Starting timer\n",
    "        t0 = time.time()   \n",
    "\n",
    "        for i in range(0,NUM_EXECUTIONS_PER_TEST):\n",
    "            mean(co_subset)\n",
    "            \n",
    "        # Stopping clock\n",
    "        t1 = time.time()\n",
    "\n",
    "        # Recording Results\n",
    "        total_time = t1-t0\n",
    "        avg_time = total_time/NUM_EXECUTIONS_PER_TEST\n",
    "\n",
    "        return total_time, avg_time\n",
    "    \n",
    "    elif test == 'sort':\n",
    "        # Starting timer\n",
    "        t0 = time.time()   \n",
    "\n",
    "        for i in range(0,NUM_EXECUTIONS_PER_TEST):\n",
    "            sort(co_subset)\n",
    "            \n",
    "        # Stopping clock\n",
    "        t1 = time.time()\n",
    "\n",
    "        # Recording Results\n",
    "        total_time = t1-t0\n",
    "        avg_time = total_time/NUM_EXECUTIONS_PER_TEST\n",
    "\n",
    "        return total_time, avg_time\n",
    "      \n",
    "    elif test == 'merge':\n",
    "        # Starting timer\n",
    "        t0 = time.time()   \n",
    "\n",
    "        for i in range(0,NUM_EXECUTIONS_PER_TEST):\n",
    "            merge(co_subset, station_co_df)\n",
    "            \n",
    "        # Stopping clock\n",
    "        t1 = time.time()\n",
    "\n",
    "        # Recording Results\n",
    "        total_time = t1-t0\n",
    "        avg_time = total_time/NUM_EXECUTIONS_PER_TEST\n",
    "\n",
    "        return total_time, avg_time\n",
    "    elif test == 'filter':\n",
    "        # Starting timer\n",
    "        t0 = time.time()   \n",
    "\n",
    "        for i in range(0,NUM_EXECUTIONS_PER_TEST):\n",
    "            filters(co_subset)\n",
    "            \n",
    "        # Stopping clock\n",
    "        t1 = time.time()\n",
    "\n",
    "        # Recording Results\n",
    "        total_time = t1-t0\n",
    "        avg_time = total_time/NUM_EXECUTIONS_PER_TEST\n",
    "\n",
    "        return total_time, avg_time\n",
    "    else:\n",
    "        # Starting timer\n",
    "        t0 = time.time()   \n",
    "\n",
    "        for i in range(0,NUM_EXECUTIONS_PER_TEST):\n",
    "            all_tests(co_subset, station_co_df)\n",
    "            \n",
    "        # Stopping clock\n",
    "        t1 = time.time()\n",
    "\n",
    "        # Recording Results\n",
    "        total_time = t1-t0\n",
    "        avg_time = total_time/NUM_EXECUTIONS_PER_TEST\n",
    "\n",
    "        return total_time, avg_time\n",
    "        \n",
    "          \n",
    "    # Stopping clock\n",
    "    t1 = time.time()\n",
    "    \n",
    "    # Recording Results\n",
    "    total_time = t1-t0\n",
    "    avg_time = total_time/NUM_EXECUTIONS_PER_TEST\n",
    "    \n",
    "    return total_time, avg_time\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0db4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_START_ROWS = 2500\n",
    "\n",
    "NUM_EXECUTIONS_PER_TEST = 3\n",
    "\n",
    "NUM_DSIZE_DOUBLINGS = 11\n",
    "# NUM_DSIZE_DOUBLINGS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92911255",
   "metadata": {},
   "source": [
    "## Executing Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a79158",
   "metadata": {},
   "source": [
    "### RAPIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceaa348",
   "metadata": {},
   "outputs": [],
   "source": [
    "numRows = NUM_START_ROWS\n",
    "\n",
    "rapids = []\n",
    "for i in range(0, NUM_DSIZE_DOUBLINGS):\n",
    "    print('Test:', i)\n",
    "    \n",
    "    numRows = numRows * 2\n",
    "    \n",
    "    if numRows > len(co_df):\n",
    "        co_subset = co_subset.append(co_subset)\n",
    "    else:\n",
    "        co_subset = co_df.iloc[0:numRows]\n",
    "        \n",
    "    # ******************************************************************************\n",
    "    # MEAN TEST\n",
    "    \n",
    "    test = {'Test':'Mean'}\n",
    "    total_time, avg_time = tester('mean', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    rapids.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # SORT TEST\n",
    "    \n",
    "    test = {'Test':'Sort'}\n",
    "    \n",
    "    total_time, avg_time = tester('sort', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    rapids.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # MERGE TEST\n",
    "    \n",
    "    test = {'Test':'Merge'}\n",
    "    \n",
    "    total_time, avg_time = tester('merge', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    rapids.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # FILTER TEST\n",
    "    \n",
    "    test = {'Test':'Filter'}\n",
    "    \n",
    "    total_time, avg_time = tester('filter', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "        \n",
    "    rapids.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # ALL TEST\n",
    "    \n",
    "    test = {'Test':'All'}\n",
    "    \n",
    "    total_time, avg_time = tester('all', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    rapids.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "results_df_rapids = pd.DataFrame(rapids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d9ea58",
   "metadata": {},
   "source": [
    "### PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e4e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving all DFs to CPU for pandas\n",
    "co_df = co_df.to_pandas()\n",
    "station_co_df = station_co_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee1c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "numRows = NUM_START_ROWS\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(0, NUM_DSIZE_DOUBLINGS):\n",
    "    print('Test:', i)\n",
    "    numRows = numRows * 2\n",
    "    \n",
    "    if numRows > len(co_df):\n",
    "        co_subset = co_subset.append(co_subset)\n",
    "    else:\n",
    "        co_subset = co_df.iloc[0:numRows]\n",
    "        \n",
    "    dfSize_GB = sys.getsizeof(co_subset) * 10**(-9)\n",
    "        \n",
    "    # ******************************************************************************\n",
    "    # MEAN TEST\n",
    "    \n",
    "    test = {'Test Size':dfSize_GB, 'Test':'Mean'}\n",
    "    total_time, avg_time = tester('mean', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    results.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # SORT TEST\n",
    "    \n",
    "    test = {'Test Size':dfSize_GB, 'Test':'Sort'}\n",
    "    \n",
    "    total_time, avg_time = tester('sort', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    results.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # MERGE TEST\n",
    "    \n",
    "    test = {'Test Size':dfSize_GB, 'Test':'Merge'}\n",
    "    \n",
    "    total_time, avg_time = tester('merge', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    results.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # FILTER TEST\n",
    "    \n",
    "    test = {'Test Size':dfSize_GB, 'Test':'Filter'}\n",
    "    \n",
    "    total_time, avg_time = tester('filter', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "        \n",
    "    results.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "    # ALL TEST\n",
    "    \n",
    "    test = {'Test Size':dfSize_GB, 'Test':'All'}\n",
    "    \n",
    "    total_time, avg_time = tester('all', co_subset, station_co_df, NUM_EXECUTIONS_PER_TEST)\n",
    "    \n",
    "    test['Total'] = total_time\n",
    "    test['Average'] = avg_time\n",
    "    \n",
    "    results.append(test)\n",
    "    \n",
    "    # ******************************************************************************\n",
    "    \n",
    "results_df_pandas = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf264b3e",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat( \n",
    "    [\n",
    "        pd.concat({\"Pandas\": results_df_pandas}, axis=1), \n",
    "        pd.concat({\"Rapids\": results_df_rapids}, axis=1)\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467604a0",
   "metadata": {},
   "source": [
    "## Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de58d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[ 'MPLCONFIGDIR' ] = '/tmp/'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eda02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the plot that is used\n",
    "def plot(axs, averages_pandas, averages_rapids, test):\n",
    "    axs.bar(x = ind, \n",
    "            height=averages_pandas, \n",
    "            width = width, \n",
    "            color='royalblue', label='Pandas')\n",
    "\n",
    "    axs.bar(ind+width, \n",
    "                height=averages_rapids, \n",
    "                width = width, \n",
    "                color='seagreen',label='Rapids')\n",
    "\n",
    "    axs.set_ylabel('Average Time (s)')\n",
    "    axs.set_xlabel('Data Set Size (GB)')\n",
    "    axs.set_title(f\"Test: {test}\",fontweight=\"bold\", fontsize=12)\n",
    "    axs.legend(loc='upper right')\n",
    "    axs.set_xticks(ticks=ind + width/2, \n",
    "              labels=bar_labels)\n",
    "    return axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the plot matrix\n",
    "\n",
    "# Computing an array to hold the test names\n",
    "tests = np.append(results_df_pandas['Test'].drop_duplicates().values,'None').reshape((3,2))\n",
    "\n",
    "# Defining the figure\n",
    "fig = plt.figure(constrained_layout=True,figsize=(3,3))\n",
    "fig.tight_layout(pad=5.0)\n",
    "\n",
    "fig.suptitle('Pandas vs Rapids Timing Comparison', fontsize=20, fontweight=\"bold\")\n",
    "\n",
    "# Setting the fig size\n",
    "fig.set_size_inches(20, 10)\n",
    "\n",
    "# Creating the subfigures\n",
    "subfigs = fig.subfigures(2, 1, wspace=1,height_ratios=[2, 1.])\n",
    "axs = subfigs[0].subplots(2, 2)\n",
    "\n",
    "# Setting the number of bars\n",
    "ind = np.arange(NUM_DSIZE_DOUBLINGS)\n",
    "\n",
    "# Defining the width between the bars\n",
    "width = 0.35\n",
    "\n",
    "# Defining the bar labels\n",
    "bar_labels = np.round(results_df_pandas['Test Size'].drop_duplicates(), 3).astype(str) + \" GB\"\n",
    "\n",
    "# Creating the plots\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 2):\n",
    "        test = tests[i, j]            \n",
    "        plot(axs[i,j], \n",
    "             results_df_pandas[results_df_pandas['Test'] == test]['Average'],\n",
    "             results_df_rapids[results_df_rapids['Test'] == test]['Average'],\n",
    "             test)\n",
    "# Creating the bottom plot since there is an odd number\n",
    "ax = subfigs[1].subplots(1,1)\n",
    "plot(ax, \n",
    "     results_df_pandas[results_df_pandas['Test'] == 'All']['Average'],\n",
    "     results_df_rapids[results_df_rapids['Test'] == 'All']['Average'],\n",
    "     'All')\n",
    "plt.savefig('pandas_v_rapids.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
